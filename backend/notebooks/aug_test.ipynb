{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import INTENTS, ENTITIES, UTTERANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/home/h4zzkr/lab/delOS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    path = os.path.join(ROOT_DIR, 'data/resources/stopwords.txt')\n",
    "    words = open(path, 'r').read().split('\\n')[:-1]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"MODEL_DIR\"] = '../model'\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "import nlpaug.flow as naf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from config import ROOT_DIR, INTENTS, ENTITIES, UTTERANCES\n",
    "#TODO: убрать комбинации шаблонных, аугментации, мб на основе рандома решать, какие слоты заменять синонимами\n",
    "\n",
    "class DatasetBuilder:\n",
    "    def __init__(self, path2dset, max_synonyms, path2write=None, drop_stopwords=False):\n",
    "        # TODO: add synonym augmentions\n",
    "        # TODO: classes normalization: too many classes of ones\n",
    "        self.path = Path(os.path.join(ROOT_DIR, path2dset))\n",
    "        self.out = os.path.join(ROOT_DIR, path2write)\n",
    "        self.max_synonyms = max_synonyms\n",
    "        self.intent_vocab = []\n",
    "        self.tag_vocab = []\n",
    "\n",
    "    def write_intent_vocab(self):\n",
    "        with open(os.path.join(self.path.parent, 'vocab.intent'), 'w') as file:\n",
    "            for i in self.intent_vocab:\n",
    "                file.write(i + '\\n')\n",
    "\n",
    "    def write_tag_vocab(self):\n",
    "        with open(os.path.join(self.path.parent, 'vocab.tag'), 'w') as file:\n",
    "            for i in self.tag_vocab:\n",
    "                file.write('B-' + i + '\\n')\n",
    "                file.write('I-' + i + '\\n')\n",
    "\n",
    "    def augment_intent(slot_map, intent):\n",
    "        pass\n",
    "\n",
    "        \n",
    "    def build_dataset(self):\n",
    "        dset = self.read_yaml()\n",
    "        raw_intents, raw_entities = dset[INTENTS], dset[ENTITIES]\n",
    "        self.entities_vocab = self.build_entities_vocab(raw_entities)\n",
    "        print('building maps for intent tempaltes...')\n",
    "        processed_intents = self.read_slots_from_yaml(raw_intents)\n",
    "        print('starting to combine entities...')\n",
    "        df = self.build_combination_sequence(processed_intents)\n",
    "        print(f'{len(df)} unique examples builded')\n",
    "        self.write_intent_vocab(); self.write_tag_vocab()\n",
    "        if self.out:\n",
    "            df.to_csv(self.out, index=False)\n",
    "        else:\n",
    "            return df\n",
    "        \n",
    "    def read_yaml(self):\n",
    "        with open(self.path) as file:\n",
    "            data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        return data\n",
    "        \n",
    "    def build_entities_vocab(self, raw_entities):\n",
    "        vocab = {}\n",
    "        for e in raw_entities:\n",
    "            values = []\n",
    "            for v in e['values']:\n",
    "                values.append(v[:self.max_synonyms])\n",
    "            name = f\"{e['type']}:{e['name']}\"\n",
    "            vocab.update({name : values})\n",
    "            self.tag_vocab.append(name)\n",
    "        return vocab\n",
    "    \n",
    "    def read_slots_from_yaml(self, raw_intents):\n",
    "        intents = []\n",
    "        for intent_class in raw_intents:\n",
    "            intent_name = intent_class['name']\n",
    "            self.intent_vocab.append(intent_name)\n",
    "            for i in intent_class[UTTERANCES]:\n",
    "                tag_class_ids = [j.span() for j in re.finditer(r'\\[(.*?)\\]', i)]\n",
    "                tag_class, tag_names = [], []\n",
    "                for t in tag_class_ids:\n",
    "                    tag_class.append(i[t[0]:t[1]].replace('[', '').replace(']', ''))\n",
    "                i = re.sub(r'\\[(.*?)\\]', '', i)\n",
    "                tag_ids = [j.span() for j in re.finditer(r'\\((.*?)\\)', i)]\n",
    "                for t in tag_ids:\n",
    "                    tag_names.append(i[t[0]:t[1]].replace('(', '').replace(')', ''))\n",
    "                tag_map = list(zip(tag_class, tag_names))\n",
    "                intent_pair = [intent_name, i, tag_map]\n",
    "                intents.append(intent_pair)\n",
    "        return intents\n",
    "    \n",
    "    def augment(self, text):\n",
    "        aug = naw.ContextualWordEmbsAug(\n",
    "        model_path='bert-base-uncased', action=\"insert\")\n",
    "        augmented_text = aug.augment(text)\n",
    "        print(\"Original:\")\n",
    "        print(text)\n",
    "        print(\"Augmented Text:\")\n",
    "        print(augmented_text)\n",
    "\n",
    "    def make_line(self, iclass, intent, imap):\n",
    "        intent_len = len(intent.split())\n",
    "        mask = ['O'] * intent_len\n",
    "        for key in imap:\n",
    "            slot_class, slot = key\n",
    "            # pos =\n",
    "            pos = [j.span() for j in re.finditer(f'({slot})', intent)][0]\n",
    "            pos = len(intent[:pos[0]].split()) - 1\n",
    "            slot_len = len(slot.split())\n",
    "            if slot_len > 1:\n",
    "                mask[pos] = 'B-' + slot_class\n",
    "                for i in range(1, slot_len):\n",
    "                    mask[pos+1] = 'I-' + slot_class\n",
    "            else:\n",
    "                mask[pos] = 'B-' + slot_class\n",
    "        text = intent.replace('(', '').replace(')', '')\n",
    "        mask = ' '.join(mask)\n",
    "        return (iclass, text, mask, intent_len)\n",
    "                              \n",
    "            \n",
    "    def build_combination_sequence(self, p_intents):\n",
    "        df = pd.DataFrame(columns=['intent_label', 'words', 'word_labels', 'length'])\n",
    "        cnter = 0\n",
    "        for i in p_intents:\n",
    "            intent_class, intent, map_ = i\n",
    "            df.loc[cnter] = self.make_line(intent_class, intent, map_)\n",
    "            cnter += 1\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'enable lights in the bedroom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = naf.Sequential([\n",
    "    naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\"),\n",
    "    naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"substitute\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enable outdoor lights in the park', 'enable lights blazing into the bedroom', 'enable lights in the spare bedroom', 'enable additional lights in his bedroom', 'enable lights in the second .', 'the lights on in the bedroom', 'enable clothing allowed in the bedroom', 'the lights in all the bedroom', 'enable lights on in his bedroom', 'enable it on in the bedroom']\n"
     ]
    }
   ],
   "source": [
    "augs = []\n",
    "cnt = 0\n",
    "aug_num = 10\n",
    "while cnt != aug_num:\n",
    "    aug_text = aug.augment(text)\n",
    "#     if 'i ' in aug_text or ' they ' in aug_text or ' we ' in aug_text:\n",
    "#         pass\n",
    "#     else:\n",
    "    augs.append(aug_text)\n",
    "    cnt += 1\n",
    "print(augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building maps for intent tempaltes...\n",
      "starting to combine entities...\n",
      "33 unique examples builded\n"
     ]
    }
   ],
   "source": [
    "builder = DatasetBuilder(path2dset='data/nlu_data/custom/dataset.yaml',\n",
    "                        max_synonyms=3,\n",
    "                        path2write='data/nlu_data/custom/train.csv')\n",
    "builder.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = pd.read_csv('/home/h4zzkr/lab/delOS/data/nlu_data/custom/train.csv')\n",
    "snips = pd.read_csv('/home/h4zzkr/lab/delOS/data/nlu_data/merged/train.csv')\n",
    "custom = custom.reset_index()\n",
    "df = pd.concat((snips, custom))\n",
    "# df.to_csv('/home/h4zzkr/lab/delOS/data/nlu_data/custom2/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d02f1adb44bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4602\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.length = df.length.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'level_0', 'intent_label', 'words', 'word_labels', 'length'], dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index', 'level_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>intent_label</th>\n",
       "      <th>words</th>\n",
       "      <th>word_labels</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>Add Don and Sherri to my Meditate to Sounds of...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name O ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>put United Abominations onto my rare groove pl...</td>\n",
       "      <td>O B-entity_name I-entity_name O B-playlist_own...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add the tune by misato watanabe to the Trapeo ...</td>\n",
       "      <td>O O B-music_item O B-artist I-artist O O B-pla...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add this artist to my this is miguel bosé play...</td>\n",
       "      <td>O O B-music_item O B-playlist_owner B-playlist...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add heresy and the hotel choir to the evening ...</td>\n",
       "      <td>O B-entity_name I-entity_name I-entity_name I-...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13161</th>\n",
       "      <td>13161</td>\n",
       "      <td>turnLightOn</td>\n",
       "      <td>turn back on lights in the loft</td>\n",
       "      <td>O O O O O O B-location:room</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>13162</td>\n",
       "      <td>turnLightOn</td>\n",
       "      <td>turn on lights for the little kitchen</td>\n",
       "      <td>O O O O O O B-location:room</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13163</th>\n",
       "      <td>13163</td>\n",
       "      <td>turnLightOn</td>\n",
       "      <td>enable electric lights inside the office</td>\n",
       "      <td>O O O O O B-location:room</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>13164</td>\n",
       "      <td>turnLightOn</td>\n",
       "      <td>also enable lights within the lavatory</td>\n",
       "      <td>O O O O O B-location:room</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13165</th>\n",
       "      <td>13165</td>\n",
       "      <td>turnLightOn</td>\n",
       "      <td>turn on lights in the spare bedroom</td>\n",
       "      <td>O O O O O O B-location:room</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13166 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   intent_label  \\\n",
       "0          0  AddToPlaylist   \n",
       "1          1  AddToPlaylist   \n",
       "2          2  AddToPlaylist   \n",
       "3          3  AddToPlaylist   \n",
       "4          4  AddToPlaylist   \n",
       "...      ...            ...   \n",
       "13161  13161    turnLightOn   \n",
       "13162  13162    turnLightOn   \n",
       "13163  13163    turnLightOn   \n",
       "13164  13164    turnLightOn   \n",
       "13165  13165    turnLightOn   \n",
       "\n",
       "                                                   words  \\\n",
       "0      Add Don and Sherri to my Meditate to Sounds of...   \n",
       "1      put United Abominations onto my rare groove pl...   \n",
       "2      add the tune by misato watanabe to the Trapeo ...   \n",
       "3      add this artist to my this is miguel bosé play...   \n",
       "4      add heresy and the hotel choir to the evening ...   \n",
       "...                                                  ...   \n",
       "13161                    turn back on lights in the loft   \n",
       "13162              turn on lights for the little kitchen   \n",
       "13163           enable electric lights inside the office   \n",
       "13164             also enable lights within the lavatory   \n",
       "13165                turn on lights in the spare bedroom   \n",
       "\n",
       "                                             word_labels  length  \n",
       "0      O B-entity_name I-entity_name I-entity_name O ...      12  \n",
       "1      O B-entity_name I-entity_name O B-playlist_own...       8  \n",
       "2      O O B-music_item O B-artist I-artist O O B-pla...      10  \n",
       "3      O O B-music_item O B-playlist_owner B-playlist...      10  \n",
       "4      O B-entity_name I-entity_name I-entity_name I-...      11  \n",
       "...                                                  ...     ...  \n",
       "13161                        O O O O O O B-location:room       7  \n",
       "13162                        O O O O O O B-location:room       7  \n",
       "13163                          O O O O O B-location:room       6  \n",
       "13164                          O O O O O B-location:room       6  \n",
       "13165                        O O O O O O B-location:room       7  \n",
       "\n",
       "[13166 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/h4zzkr/lab/delOS/data/nlu_data/custom2/train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlcondaf22f2c0875804c018eabe3662a7c8e9b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
