{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys; sys.path.append(os.path.dirname(os.getcwd())); ROOT_DIR = '/home/h4zzkr/lab/delOS/'\n",
    "dataset_path = os.path.join(ROOT_DIR, 'data/nlu_data/custom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "df_valid = pd.read_csv(os.path.join(dataset_path, 'valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_names = Path(os.path.join(dataset_path, \"vocab.intent\")).read_text().split()\n",
    "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
    "intent_train = df_train[\"intent_label\"].map(intent_map).values\n",
    "intent_valid = df_valid[\"intent_label\"].map(intent_map).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2intent = {intent_map[k] : k for k in intent_map.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "featurizer = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = np.array(featurizer.encode(df_train['words']))\n",
    "encoded_valid = np.array(featurizer.encode(df_valid['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, y_true, valid_data):\n",
    "    y_pred = np.argmax(model.predict_proba(valid_data), axis=1)\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h4zzkr/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgmodel = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    C=1,\n",
    "    tol=0.00001,\n",
    "    solver='liblinear',\n",
    "    max_iter=2,\n",
    ")\n",
    "lgmodel.fit(encoded_train, intent_train)\n",
    "accuracy(lgmodel, intent_valid, encoded_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgbmodel = XGBClassifier(\n",
    "    max_depth=2,\n",
    "    gamma=0.5,\n",
    ")\n",
    "xgbmodel.fit(encoded_train, intent_train)\n",
    "accuracy(xgbmodel, intent_valid, encoded_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.activations import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassificationModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, intent_num_labels=None, dropout_prob=0.15):\n",
    "        super().__init__(name=\"\")\n",
    "        self.dropout = Dropout(dropout_prob)\n",
    "        self.intent_classifier = Dense(intent_num_labels)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        inputs = self.dropout(inputs)\n",
    "        out = self.intent_classifier(inputs)\n",
    "        out = softmax(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "densemodel = IntentClassificationModel(intent_num_labels=len(intent_map))\n",
    "optim = Adam(learning_rate=0.001, epsilon=1e-09)\n",
    "loss_f = SparseCategoricalCrossentropy(from_logits=False)\n",
    "metrics_f = [SparseCategoricalAccuracy('accuracy')]\n",
    "\n",
    "densemodel.compile(optimizer=optim,\n",
    "                     loss=loss_f,\n",
    "                     metrics=metrics_f\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.8220 - accuracy: 0.4318 - val_loss: 0.7393 - val_accuracy: 0.5000\n",
      "Epoch 2/9\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6759 - accuracy: 0.6591 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 3/9\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 0.4013 - val_accuracy: 1.0000\n",
      "Epoch 4/9\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4295 - accuracy: 0.8409 - val_loss: 0.3030 - val_accuracy: 1.0000\n",
      "Epoch 5/9\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3990 - accuracy: 0.8409 - val_loss: 0.2336 - val_accuracy: 1.0000\n",
      "Epoch 6/9\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3636 - accuracy: 0.8409 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 7/9\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3071 - accuracy: 0.8636 - val_loss: 0.1546 - val_accuracy: 1.0000\n",
      "Epoch 8/9\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2425 - accuracy: 0.9091 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
      "Epoch 9/9\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1966 - accuracy: 0.9545 - val_loss: 0.1069 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = densemodel.fit(encoded_train, intent_train, epochs=9, batch_size=32,\n",
    "                           validation_data=(encoded_valid, intent_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'turnLightOn'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_output(inp, encoder, model, id2intent):\n",
    "    inp = np.array(encoder.encode(inp))\n",
    "    out = np.argmax(np.array(model(inp)))\n",
    "    return id2intent[out]\n",
    "    \n",
    "inp = 'so dark, please turn on the light'\n",
    "test_output(inp, featurizer, densemodel, id2intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc_output(inp, encoder, model, valid, id2intent):\n",
    "    clas = test_output(inp, encoder, model, id2intent)\n",
    "    return clas, valid == clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on lights for the little kitchen ('turnLightOn', True)\n",
      "enable electric lights inside the office ('turnLightOn', True)\n",
      "cut the lights down in the house ('turnLightOff', True)\n",
      "turn off the bathroom lights ('turnLightOff', True)\n",
      "light on ('turnLightOn', True)\n",
      "turn off the lights next door ('turnLightOff', True)\n",
      "turn off the light ('turnLightOff', True)\n",
      "disable the house lights in across the garage ('turnLightOff', True)\n",
      "disable the illumination in the kitchen please ('turnLightOff', True)\n",
      "can you turn off the light here ('turnLightOff', True)\n",
      "turn on light upstairs ('turnLightOn', True)\n",
      "enable light in the bedroom ('turnLightOn', True)\n"
     ]
    }
   ],
   "source": [
    "for (i, c) in zip(df_valid['words'], df_valid['intent_label']):\n",
    "    print(i, test_acc_output(i, featurizer, densemodel, c, id2intent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlcondaf22f2c0875804c018eabe3662a7c8e9b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
